<!DOCTYPE html><html><head><meta charset="utf-8"><link rel="stylesheet" href="/_astro/acceleration-ball.BLcaXhsC.css"></head><header id="header" class="fixed top-0 left-0 right-0 z-50 hidden md:block transition-all duration-300" data-astro-cid-3ef6ksr2> <!-- header bad: class="fixed top-0 left-0 right-0 z-50 hidden md:block transition-all duration-300 bg-white border-b border-gray-200" --> <nav class="max-w-7xl mx-auto px-8 py-4" data-astro-cid-3ef6ksr2> <ul class="flex items-center gap-8 justify-center" data-astro-cid-3ef6ksr2> <li data-astro-cid-3ef6ksr2> <a href="/#about" class="text-gray-700 hover:text-black transition-colors font-medium" data-astro-cid-3ef6ksr2>
About
</a> </li> <li data-astro-cid-3ef6ksr2> <a href="/#projects" class="text-gray-700 hover:text-black transition-colors font-medium" data-astro-cid-3ef6ksr2>
Projects
</a> </li> <!--{
        hasExperience && (
          <li>
            <a
              href="#experience"
              class="text-gray-700 hover:text-black transition-colors font-medium"
            >
              Experience
            </a>
          </li>
        )
      }
      {
        hasEducation && (
          <li>
            <a
              href="#education"
              class="text-gray-700 hover:text-black transition-colors font-medium"
            >
              Education
            </a>
          </li>
        )
      }
      --> </ul> </nav> </header> <script type="module">window.addEventListener("scroll",()=>{const e=document.getElementById("header");window.scrollY>100?e?.classList.add("bg-white/80","backdrop-blur-sm"):e?.classList.remove("bg-white/80","backdrop-blur-sm")});</script>  <main class="mt-32 px-4 max-w-3xl mx-auto space-y-6"> <h1 class="text-3xl font-bold mb-8">
Master's Thesis &mdash; Clustering and Classifying Radar Data using Deep Learning
</h1> <b>In the context of surveillance, intelligent radars can guess what a blob of radar detections encompasses. It may be unnecessary to call the guards if a rabbit enters the monitored area, but if a person or a vehicle does so, measures may be required.</b> <p>To perform such a guess, or classification, all detections sampled by the radar are first clustered (grouped together) based on the detections’ spatial coordinates. Different clusters are assumed to comprise distinct objects. By observing the size of an object, radial velocity, and tracking how it moves in time, the class of the object is guessed, for example 'human', 'car', or 'rabbit'.</p> <img src="/images/masters-thesis/pipeline.png" alt="Pipeline incl. clustering, tracking, and classification" class="my-6 border border-gray-300 rounded-md"> <p>With this thesis we aim to improve upon the clustering step. In the original pipeline, clustering is performed considering only the detections’ spatial coordinates, x and y. By first guessing the class of every detection in the monitored scene, however, it should be possible to cluster the detections more accurately.</p> <p>Combining the clustering output with our guesses for each detection in the scene, we also get an alternative way of classifying objects: taking the most frequent class prediction of all the detections that comprise an object. If these classifications outperform those of the original pipeline, we would also be able to improve upon the classification step of the pipeline.</p> <p>To guess the class of each detection, we use deep neural networks that learn from the data we feed them. The main network we investigate is PointNet++, from 2017. It learns features hierarchically at different scales, much like CNNs, which dominate the field of computer vision for camera images. CNNs can be seen as a mathematical replication of the functionality of a biological eye-brain combination, with neurons acting at different scales to extract features of objects at different abstraction levels, as discovered by Hubel and Wiesel.</p> <p>The results are promising, and on par with the original pipeline, both for clustering and classification of objects. We show that the results improve with the amount of training data. We have also noted that the data contains some misleading labels for what is the ground truth. Thus, if more data was collected and the quality of the data was improved, we could improve upon the original pipeline.</p> <p>Our hope is that classification could also be performed faster than the original pipeline. So if a human enters a scene, it can be labeled as a human more quickly, decreasing the probability of it leaving the scene before being classified. This would be very beneficial to the end user, in the context of surveillance.</p> <img src="/images/masters-thesis/semseg_gt.png" alt="Radar visualization" class="my-6 border border-gray-300 rounded-md"> </main> <footer class="relative bg-gray-50 border-t border-gray-200"> <div class="mx-auto max-w-6xl px-6 py-12 lg:px-8"> <div class="flex flex-col md:flex-row md:items-center md:justify-between gap-8"> <div class="flex flex-col gap-4"> <h3 class="text-2xl font-bold text-gray-800"> Jonatan Lindholm </h3> <p class="text-base text-gray-600"> Software Engineer </p> <div class="flex gap-x-6"> <a href="https://linkedin.com/in/jonatan-lindholm-8aa005a9" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn" class="text-gray-600 transition-colors duration-300 hover:text-[var(--accent-color)]" style="--accent-color: #1e2420ff"> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-6 w-6"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M8 11v5"></path><path d="M8 8v.01"></path><path d="M12 16v-5"></path><path d="M16 16v-3a2 2 0 1 0 -4 0"></path><path d="M3 7a4 4 0 0 1 4 -4h10a4 4 0 0 1 4 4v10a4 4 0 0 1 -4 4h-10a4 4 0 0 1 -4 -4z"></path></svg> </a> <a href="https://github.com/JontAmazon" target="_blank" rel="noopener noreferrer" aria-label="GitHub" class="text-gray-600 transition-colors duration-300 hover:text-[var(--accent-color)]" style="--accent-color: #1e2420ff"> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-6 w-6"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5"></path></svg> </a> </div> </div> <div class="hidden md:block flex flex-col md:items-end gap-4"> <nav class="flex gap-x-8"> <a href="/#about" class="text-sm text-gray-600 hover:text-gray-800 transition-colors">About</a> <a href="/#projects" class="text-sm text-gray-600 hover:text-gray-800 transition-colors">
Projects
</a> <!--{
            hasExperience && (
              <a
                href="#experience"
                class="text-sm text-gray-600 hover:text-gray-800 transition-colors"
              >
                Experience
              </a>
            )
          }
          {
            hasEducation && (
              <a
                href="#education"
                class="text-sm text-gray-600 hover:text-gray-800 transition-colors"
              >
                Education
              </a>
            )
          }
          --> </nav> <p class="text-sm text-gray-500">
© 2025 Jonatan Lindholm.
</p> </div> </div> </div> <!-- Decorative pattern --> <div class="absolute inset-0 -z-10 overflow-hidden"> <svg aria-hidden="true" class="absolute bottom-0 left-0 w-full h-24 text-gray-100"> <pattern id="footer-pattern" x="0" y="0" width="100" height="100" patternUnits="userSpaceOnUse"> <path d="M0 50 Q 25 40, 50 50 T 100 50" stroke="currentColor" stroke-width="0.5" fill="none" opacity="0.4"></path> </pattern> <rect width="100%" height="100%" fill="url(#footer-pattern)"></rect> </svg> </div> </footer></html>